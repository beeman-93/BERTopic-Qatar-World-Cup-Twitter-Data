{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd3cfd-61c7-409c-8364-973786542b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import random \n",
    "\n",
    "with open('world_cup_tweets.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "tweets = data.Tweet_processed.to_list()\n",
    "tweets = random.sample(tweets, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1b8ee-f274-4a6e-bb59-787634a91451",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "hf_token = \"YOUR OWN TOKEN\"\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/\" + model\n",
    "headers = {\"Authorization\": \"Bearer %s\" % (hf_token)}\n",
    "\n",
    "def analysis(data):\n",
    "    payload = dict(inputs=data, options=dict(wait_for_model=True))\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb9fa7-aff3-4ca5-885c-646f8a1d3efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following is the code for doing Topic Based Sentiment Analysis. \n",
    "# Not only we need to get the higher score, \n",
    "# we need to store the sentiment probability score for every tweet for further calculation. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tweets_analysis = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    try:\n",
    "        sentiment_result = analysis(tweet)[0]\n",
    "        sentiment_probabilities = {label['label']: label['score'] for label in sentiment_result}\n",
    "        tweets_analysis.append({'tweet': tweet, **sentiment_probabilities})\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccada56b-4485-4ece-b7fd-6e03aa28ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(tweets_analysis, columns=['tweet'] + list(sentiment_probabilities.keys()))\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.head()\n",
    "df.to_pickle('world_cup_tweets_sentiment_score.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05e532-49e7-467d-9b0b-05d4594aff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=df['tweet']\n",
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
    "topics, probs = topic_model.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334bf21-e903-4737-ba9c-b8d2297dd484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(topic_model.get_document_info(texts))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf52474-7eeb-4c43-8ce0-dc14fa60a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df,df2, how='inner', left_on = 'tweet', right_on = 'Document')\n",
    "df_merge = df_merge.drop('Document', axis=1)\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fbdbdc-5824-4fe1-a66c-65fc4b4973fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sentiment = df_merge.groupby('Topic').agg({'neutral': 'mean', 'positive': 'mean', 'negative': 'mean'})\n",
    "df_topic_sentiment = df_topic_sentiment.reset_index()\n",
    "df_topic_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b72ad-3802-4836-b222-be55a3cd154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = topic_model.get_topic_info()\n",
    "df_freq = pd.DataFrame(freq)\n",
    "df_new = pd.merge (df_freq, df_topic_sentiment, how = 'inner', on = 'Topic' )\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221ab34-9f6d-48b6-9b69-232295af6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column with the highest score\n",
    "score_cols = ['neutral', 'positive', 'negative']\n",
    "df_new['highest_score'] = df_new[score_cols].max(axis=1)\n",
    "\n",
    "# define function to calculate sentiment label\n",
    "def get_sentiment(row):\n",
    "    if row['positive'] == row['highest_score']:\n",
    "        return 'positive'\n",
    "    elif row['negative'] == row['highest_score']:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# apply function to each row and create new column\n",
    "df_new['sentiment'] = df_new.apply(get_sentiment, axis=1)\n",
    "\n",
    "df_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
